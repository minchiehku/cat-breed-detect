# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BnbLaOtcenlu8gf-to7cToQ9jknN3LZk
"""

#安裝kaggle
!pip install kaggle

#上傳Kaggle的API憑證到Colab
!mkdir ~/.kaggle
!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d ma7555/cat-breeds-dataset

#解壓縮資料集
import zipfile
import os

# 壓縮檔位置
zip_file_path = '/content/cat-breeds-dataset.zip'

# 解壓目標目錄（暫存區）
extract_to_path = '/content/cat_breeds/'

# 如果目標目錄不存在，則創建目錄
os.makedirs(extract_to_path, exist_ok=True)

# 解壓縮
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_to_path)

print(f"Files extracted to {extract_to_path}")

#模型訓練
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import json
import os
from tensorflow.keras.models import load_model
import numpy as np
from tensorflow.keras.preprocessing import image

# 定義一個安全的數據生成器函數，用來跳過損壞的圖片
def safe_flow_from_directory(generator, directory, *args, **kwargs):
    inner_generator = generator.flow_from_directory(directory, *args, **kwargs)
    while True:
        try:
            batch_x, batch_y = next(inner_generator)
            yield batch_x, batch_y
        except Exception as e:
            print(f"Skipping corrupted image batch due to error: {e}")

# 設置數據生成器參數
data_dir = '/content/cat_breeds/images'
img_size = (128, 128)  # 調整圖片大小
batch_size = 32  # 設置批次大小以穩定訓練過程

# 使用 ImageDataGenerator 來進行數據增強和生成
datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

# 訓練集生成器
train_generator = safe_flow_from_directory(
    datagen,
    data_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='training'
)

# 驗證集生成器
validation_generator = safe_flow_from_directory(
    datagen,
    data_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation'
)

# 獲取類別數量和樣本數量
temp_gen = datagen.flow_from_directory(data_dir, subset='training')
num_classes = len(temp_gen.class_indices)
steps_per_epoch = temp_gen.samples // batch_size
validation_steps = datagen.flow_from_directory(data_dir, subset='validation').samples // batch_size

# 保存類別索引到 JSON 文件
class_indices = temp_gen.class_indices
class_indices_path = '/content/drive/MyDrive/cat_breed_class_indices.json'
with open(class_indices_path, 'w') as f:
    json.dump(class_indices, f)
print(f"Saved class indices to '{class_indices_path}'")
print("Number of classes:", num_classes)

# 構建模型
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))
x = Flatten()(base_model.output)
x = Dense(256, activation='relu')(x)
x = Dense(num_classes, activation='softmax')(x)  # 使用正確的類別數量
model = Model(inputs=base_model.input, outputs=x)

# 冷凍預訓練模型的層
for layer in base_model.layers:
    layer.trainable = False

# 編譯模型
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# 設置回調
early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)

checkpoint_path = '/content/drive/MyDrive/cat_breed_model_checkpoint.keras'
checkpoint = ModelCheckpoint(
    checkpoint_path,
    monitor='val_accuracy',
    save_best_only=True,
    mode='max',
    verbose=1
)

# 加載之前的模型權重（如果有）
if os.path.exists(checkpoint_path):
    print("Loading weights from the previous training session...")
    model.load_weights(checkpoint_path)
else:
    print("No previous weights found, starting training from scratch.")

# 開始訓練模型
history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=3,  # 訓練幾個 epoch
    steps_per_epoch=steps_per_epoch,
    validation_steps=validation_steps,
    callbacks=[checkpoint, early_stopping]
)

# 測試模型的分類功能
def classify_image(img_path, model, class_indices_path):
    # 加載類別索引
    with open(class_indices_path, 'r') as f:
        class_labels = json.load(f)
    class_labels = {v: k for k, v in class_labels.items()}  # 反轉字典以根據索引查找品種名稱

    # 加載和預處理圖片
    img = image.load_img(img_path, target_size=(128, 128))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0) / 255.0

    # 進行預測
    predictions = model.predict(img_array)
    predicted_class = np.argmax(predictions, axis=1)[0]
    breed_name = class_labels[predicted_class]
    confidence = predictions[0][predicted_class]

    print(f"Predicted breed: {breed_name} with confidence: {confidence:.2f}")

# 使用示例
test_image_path = '/content/drive/MyDrive/Colab Notebooks/NameTheCat/test.jpg'
classify_image(test_image_path, model, class_indices_path)

import matplotlib.pyplot as plt

# 繪製準確率曲線
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# 繪製損失曲線
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()